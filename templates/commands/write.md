---
description: 撰写文章初稿
argument-hint: [项目编号或specification路径]
allowed-tools: Read(//*), Write(//workspaces/**/draft.md)
scripts:
  sh: .specify/scripts/bash/write.sh
---

# 撰写初稿

## 核心原则

- **真实素材优先**: 优先使用 materials-found.md 中的真实经历
- **保留创作痕迹**: 初稿允许不完美,后续有三遍审校优化
- **严格遵循spec**: 按照 specification.md 的结构和字数要求

---

## 功能说明

基于前期准备的所有材料,撰写文章初稿:
- Brief (需求)
- 调研报告 (数据支持)
- Specification (结构和定位)
- Materials Found (真实素材)

---

## 输入方式

### 方式1: 指定项目编号
```bash
/write 001
```

### 方式2: 指定specification路径
```bash
/write workspaces/wechat/articles/001-claude-code-评测/specification.md
```

### 方式3: 自动推断
```bash
/write
```

---

## 处理流程

### 1️⃣ 读取所有上下文

**必读文件:**

1. **Brief** (`_briefs/001-*-brief.md`)
   - 了解基本需求和限制

2. **调研报告** (`_knowledge_base/001-调研报告-*.md`)
   - 获取事实数据和参考资料

3. **Specification** (`workspaces/*/articles/001-*/specification.md`)
   - 核心参考: 结构、字数、风格要求

4. **Materials Found** (`workspaces/*/articles/001-*/materials-found.md`)
   - 真实素材(如有)

**输出概览:**

```
📋 项目概览:
- 项目: 001-claude-code-评测
- 标题方向: Claude Code vs Cursor 深度对比
- 字数目标: 3000字 (±10%)
- 选题方向: 真实场景测试对比
- 真实素材: 5条(高相关3条)
- 调研数据: 18条参考资料

📝 文章结构 (来自specification.md):
1. 引言 (300字) - 为什么做这次对比
2. 场景1: 重构遗留代码 (600字)
3. 场景2: 新功能开发 (600字)
4. 场景3: Bug修复 (600字)
5. 场景4: 代码审查 (600字)
6. 场景5: 文档生成 (300字)
7. 综合对比与建议 (300字)

✅ 开始撰写...
```

---

### 2️⃣ 撰写初稿

**写作策略:**

#### A. 按结构逐部分撰写

**严格遵循**:
- Specification 中的章节划分
- 每部分的字数要求(±10%)
- 内容要点清单

**示例: 引言部分**

```markdown
## 引言 (目标300字,当前298字)

作为一名日常深度依赖 AI 编程工具的开发者,我在过去三个月持续使用了 Claude Code 和 Cursor 两款主流工具。网上的评测文章很多,但大多停留在功能清单对比,缺少真实场景的深度测试。

因此,我设计了5个覆盖日常开发80%场景的测试用例:重构遗留代码、新功能开发、Bug修复、代码审查和文档生成。每个场景我都用两款工具完整走了一遍,记录耗时、准确度和使用体验。

[来源: 真实素材 - materials-found.md 素材1改写]

这篇文章不追求"谁更好"的答案,而是通过真实数据,帮你找到"什么场景用什么工具"的选择方法。

[300字检查: ✓]
```

#### B. 融入真实素材

**改写策略:**

**原始素材**(口语化):
```
试用了一周 Claude Code,感觉比 Cursor 更理解我的意图。
今天重构一个老项目,Claude 直接看懂了我的架构,
Cursor 还需要我多解释几遍。不过 Cursor 的补全速度确实更快。
```

**改写后**(书面语):
```
在重构测试中,Claude Code 展现出了更强的代码理解能力。
面对一个包含自定义架构的老项目,Claude Code 能够快速识别
依赖关系并给出合理的重构建议,而 Cursor 则需要更多的上下文
提示才能理解设计意图。不过,Cursor 在代码补全速度上确实更胜一筹。
```

**改写原则:**
- ✅ 保留核心观点和真实感
- ✅ 转换为书面语
- ✅ 补充必要的技术细节
- ❌ 不编造素材中没有的内容

#### C. 引用调研数据

**数据引用规范:**

```markdown
根据官方文档,Claude Code 基于 Claude 3.5 Sonnet 模型[1],
而 Cursor 则集成了多个模型供用户选择[2]。

在性能测试中,Cursor 的代码补全平均响应时间为 1.2秒,
Claude Code 为 2.8秒[3]。

[1] Claude Code官方文档, 2025-01
[2] Cursor Features页面, 2025-01
[3] 笔者实测,测试环境: MacBook Pro M2, 网络延迟<100ms
```

**注意:**
- 官方数据必须标注来源URL或文档
- 自己测试的数据要说明测试条件
- 时效性信息要标注日期

#### D. 字数控制

**实时字数检查:**

在每个章节结束后,标注当前字数:
```markdown
## 场景1: 重构遗留代码 (目标600字,当前585字)

[内容...]

[✓ 字数检查: 585/600, 在±10%范围内]
```

**字数调整:**
- 超出10%: 精简冗余内容,合并相似观点
- 不足10%: 补充细节,增加案例

---

### 3️⃣ 初稿自查

**完成初稿后,进行快速自查:**

#### 结构检查
- [ ] 是否严格按照specification的结构?
- [ ] 是否每个章节都覆盖了要点清单?
- [ ] 字数是否在目标范围内(±10%)?

#### 内容检查
- [ ] 真实素材是否都有效融入?
- [ ] 数据引用是否标注来源?
- [ ] 是否有明显的逻辑漏洞或矛盾?

#### 风格检查
- [ ] 是否符合specification的语言风格?
- [ ] 开头是否吸引人?
- [ ] 结尾是否有明确结论/建议?

**⚠️ 注意**: 这是初稿自查,不求完美。后续有三遍审校会系统化优化。

---

### 4️⃣ 保存初稿

**文件路径:**
```
workspaces/wechat/articles/001-claude-code-评测/draft.md
```

**文件格式:**

```markdown
# [标题 - 待最终确定]

**项目编号**: 001
**字数**: 3050字 (目标3000字)
**创建时间**: 2025-01-15 16:30
**状态**: 初稿完成,待审校

---

## 标题备选:
1. Claude Code vs Cursor: 5个真实场景深度对比
2. AI编程助手实战评测: Claude Code 和 Cursor 哪个更适合你?
3. 用数据说话: Claude Code 与 Cursor 的真实使用体验对比

[待 /review 后最终确定]

---

## 正文

### 引言

作为一名日常深度依赖 AI 编程工具的开发者...

[字数: 298/300]

---

### 场景1: 重构遗留代码

[内容...]

[字数: 585/600]

---

[... 其他章节 ...]

---

## 参考资料

[1] Claude Code官方文档, https://...
[2] Cursor Features, https://...
[3] ...

---

## 使用的真实素材清单

- ✓ 素材1: 重构老项目体验 (materials-found.md)
- ✓ 素材3: 多工具对比笔记 (materials-found.md)
- ✓ 素材2: 价格敏感度讨论 (materials-found.md)

---

## 待审校事项

### 内容层面 (content审校)
- [ ] 检查逻辑是否严密
- [ ] 验证数据准确性
- [ ] 补充遗漏要点

### 风格层面 (style审校)
- [ ] 降低AI味
- [ ] 优化语言节奏
- [ ] 增强真实感

### 细节层面 (detail审校)
- [ ] 修正标点符号
- [ ] 优化排版格式
- [ ] 最终字数微调
```

---

### 5️⃣ 输出总结并等待用户选择

**AI向用户展示:**

```
✅ 初稿撰写完成！

📄 文件位置:
workspaces/wechat/articles/001-claude-code-评测/draft.md

📊 初稿概况:
- 总字数: 3050字 (目标3000字, +1.7%)
- 结构: 7个部分,完全按照specification
- 真实素材使用: 5条中使用了3条(高相关)
- 调研数据引用: 12处
- 参考资料: 18条

💡 素材使用情况:
✓ 素材1 (⭐⭐⭐⭐⭐): 已用于"重构场景"和"引言"
✓ 素材3 (⭐⭐⭐⭐⭐): 已用于"综合对比"
✓ 素材2 (⭐⭐⭐⭐): 已用于"价格讨论"
○ 素材4 (⭐⭐⭐): 未使用(相关度较低)
○ 素材5 (⭐⭐): 未使用(相关度低)

⚠️ 初稿说明:
这是第一版,预期会有以下问题:
- AI味可能较重
- 部分表达可能生硬
- 标点和格式可能不够规范

不用担心,接下来的三遍审校会系统化优化!

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
💡 下一步操作
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

a) 自动三遍审校 (推荐)
   适合: 相信 AI 按最佳实践优化文章
   说明: 我将依次执行:
         1. content 审校 (事实、逻辑、结构)
         2. style 审校 (降 AI 味、优化表达)
         3. detail 审校 (标点、排版、格式)
   预计: 15-25分钟

b) 手动选择审校顺序
   适合: 您想重点优化某个维度,或自定义审校流程
   说明: 您可以指定执行哪个审校,或调整顺序
   示例: "先 style 后 content" 或 "只做 style 审校"

c) 先查看初稿内容
   适合: 想先通读初稿,再决定如何审校
   说明: 我会展示完整的初稿内容
   提示: 查看后可以针对性修改或继续审校

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
⭐ 推荐: 选择 a) 自动三遍审校
   理由: 系统化审校能最大化降低 AI 味,提升文章质量

⚠️ 请输入 a/b/c 或直接输入审校命令(如 /review content),我将继续优化文章
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**⚠️ 强制等待机制**:
AI **必须停在这里,等待用户输入选择**,绝对不要自动开始审校

---

## 写作技巧

### 1. 开头吸引力

**❌ 平淡开头:**
```
本文将对比 Claude Code 和 Cursor 两款 AI 编程工具。
```

**✅ 吸引人的开头:**
```
"AI 编程助手到底能省多少时间?" 这是我在 Reddit 上
看到最多的问题。三个月前我也这么问,三个月后,
我用真实数据给出答案: 在最佳场景下,接近 40%。

但关键是,什么才是"最佳场景"?
```

**技巧:**
- 用问题开头,引发读者思考
- 用数据/结论制造悬念
- 建立"我也和你一样"的共鸣

### 2. 真实感营造

**❌ 纯AI生成感:**
```
经过测试,Claude Code 在代码理解方面表现优秀,
而 Cursor 则在速度方面更胜一筹。
```

**✅ 真实感表达:**
```
有一次我重构一个两年前写的项目,代码里全是当时
为了赶工留下的"技术债"。Claude Code 看了30秒,
直接指出了3个可以优化的架构问题。而 Cursor,
我得先给它解释一遍整个项目的设计思路。

这不是说 Cursor 不好,而是两者的"理解方式"不同。
```

**技巧:**
- 用具体场景替代抽象结论
- 加入时间、数字等细节
- 使用第一人称和回忆性语言

### 3. 数据可信度

**❌ 缺少上下文的数据:**
```
测试显示 Cursor 响应时间为1.2秒。
```

**✅ 可信的数据呈现:**
```
在我的测试环境(MacBook Pro M2,16GB内存,网络延迟80ms)下,
Cursor 的平均响应时间为1.2秒,Claude Code 为2.8秒。
需要说明的是,这个数据会受网络环境和服务器负载影响,
仅供参考。

[测试方法: 每个工具执行20次代码补全任务,取平均值,
剔除最高最低各2个异常值]
```

**技巧:**
- 说明测试环境
- 标注数据局限性
- 透明化测试方法

### 4. 避免绝对化表达

**❌ 容易引发争议:**
```
Claude Code 明显比 Cursor 更好。
```

**✅ 客观表达:**
```
对于需要深度理解代码架构的场景,Claude Code
的表现更符合我的预期。但如果你更在意响应速度,
Cursor 可能是更好的选择。

工具没有绝对好坏,关键看你的需求。
```

**技巧:**
- 用"在XX场景下"限定条件
- 承认不同需求有不同选择
- 使用"可能""倾向于"等限定词

---

## 注意事项

### 1. 不要偏离specification

❌ **错误做法:**
- Specification 要求写5个场景测试
- 初稿却写成了功能清单对比

✅ **正确做法:**
- 严格按照specification的结构
- 如果写作中发现结构不合理,**停下来**先调整specification,不要擅自改变

### 2. 真实素材不足时

**如果materials-found.md只有1-2条素材:**
- ✅ 在关键部分使用真实素材(如引言、核心论证)
- ✅ 其他部分可以基于调研数据生成
- ✅ 明确标注哪些是真实经历,哪些是基于资料总结
- ❌ 不要编造"假装"是真实素材的内容

### 3. 字数分配

**不要平均分配字数**:
- 核心章节可以多写(重要场景测试)
- 次要章节可以少写(背景介绍)
- 遵循specification的字数分配建议

### 4. 引言和结尾

**引言**(10%字数):
- 必须吸引人,建立阅读期待
- 说明"为什么写""为什么值得读"

**结尾**(10%字数):
- 必须有明确结论或行动建议
- 不要虎头蛇尾,草草收场

---

## 常见问题

### Q1: 写作过程中发现调研数据不够怎么办?

**A**:
1. 在初稿中标注 `[待补充数据]`
2. 完成初稿后告知用户: "XX部分缺少数据支持,建议补充调研"
3. 用户可以选择:
   - 重新执行 `/research` 补充数据
   - 调整specification,降低该部分的数据要求
   - 接受当前状态,继续审校

### Q2: 真实素材和specification要求不匹配怎么办?

**示例**: Specification要求写5个场景,但真实素材只覆盖了2个场景。

**A**:
- 2个场景使用真实素材(重点章节)
- 3个场景基于调研数据生成(辅助章节)
- 在初稿中标注: "场景3-5基于调研资料总结,场景1-2基于真实测试"

### Q3: 写到一半发现specification的结构不合理怎么办?

**A**:
**停止写作**,先解决specification问题:
1. 告知用户: "发现结构问题: [具体描述]"
2. 建议调整方案
3. 等待用户确认
4. 重新生成specification后再继续写作

**不要擅自改变结构继续写。**

### Q4: 如何平衡"真实感"和"专业性"?

**A**:
- 引言和案例部分: 侧重真实感(第一人称,具体场景)
- 数据分析部分: 侧重专业性(客观,数据驱动)
- 结论部分: 结合两者(基于数据的个人建议)

---

## 输出示例

见上文 "4️⃣ 保存初稿" 和 "5️⃣ 输出总结" 部分。

---

## 脚本支持

可选的bash脚本 `.specify/scripts/bash/write.sh` 可以:
- 检查必需文件是否存在(specification.md等)
- 创建draft.md文件骨架
- 初始化字数统计

AI会在开始写作前执行脚本并读取输出。
